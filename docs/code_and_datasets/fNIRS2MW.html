<!DOCTYPE html>
<html lang="en-US">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <title>The Tufts fNIRS to Mental Workload Dataset | Tufts HCI Lab</title>
    <meta name="generator" content="VuePress 1.8.2">
    
    <meta name="description" content="Tufts Human-Computer Interaction Laboratory">
    
    <link rel="preload" href="/assets/css/0.styles.3208571a.css" as="style"><link rel="preload" href="/assets/js/app.4c03d920.js" as="script"><link rel="preload" href="/assets/js/11.a5b16cad.js" as="script"><link rel="prefetch" href="/assets/js/10.b82a0523.js"><link rel="prefetch" href="/assets/js/12.52fe50e6.js"><link rel="prefetch" href="/assets/js/13.fc664ecd.js"><link rel="prefetch" href="/assets/js/14.03683a83.js"><link rel="prefetch" href="/assets/js/15.12b7bd5c.js"><link rel="prefetch" href="/assets/js/16.ccfaf848.js"><link rel="prefetch" href="/assets/js/17.cda8dce7.js"><link rel="prefetch" href="/assets/js/18.b704f46e.js"><link rel="prefetch" href="/assets/js/19.5ddcc200.js"><link rel="prefetch" href="/assets/js/2.5463c4c1.js"><link rel="prefetch" href="/assets/js/20.8f8302ca.js"><link rel="prefetch" href="/assets/js/21.270e6e1d.js"><link rel="prefetch" href="/assets/js/22.36db54a7.js"><link rel="prefetch" href="/assets/js/23.769e5b62.js"><link rel="prefetch" href="/assets/js/24.201b2c64.js"><link rel="prefetch" href="/assets/js/25.0e5d65c8.js"><link rel="prefetch" href="/assets/js/26.2c5bb32a.js"><link rel="prefetch" href="/assets/js/27.e62d850b.js"><link rel="prefetch" href="/assets/js/28.cc4b11bd.js"><link rel="prefetch" href="/assets/js/29.0f9e192c.js"><link rel="prefetch" href="/assets/js/3.e8f94cd8.js"><link rel="prefetch" href="/assets/js/30.fe52c01d.js"><link rel="prefetch" href="/assets/js/31.383112eb.js"><link rel="prefetch" href="/assets/js/32.3626cff6.js"><link rel="prefetch" href="/assets/js/33.778ce70b.js"><link rel="prefetch" href="/assets/js/34.89653bb3.js"><link rel="prefetch" href="/assets/js/35.515c62a7.js"><link rel="prefetch" href="/assets/js/36.ab0a0d0a.js"><link rel="prefetch" href="/assets/js/37.775cd637.js"><link rel="prefetch" href="/assets/js/38.f7b75fc9.js"><link rel="prefetch" href="/assets/js/39.3c58ec0a.js"><link rel="prefetch" href="/assets/js/4.9d16c770.js"><link rel="prefetch" href="/assets/js/5.b529b20a.js"><link rel="prefetch" href="/assets/js/6.100ef550.js"><link rel="prefetch" href="/assets/js/7.af2ba5e5.js"><link rel="prefetch" href="/assets/js/8.21a796b2.js"><link rel="prefetch" href="/assets/js/9.a04a0a07.js">
    <link rel="stylesheet" href="/assets/css/0.styles.3208571a.css">
  </head>
  <body>
    <div id="app" data-server-rendered="true"><section id="global-layout" data-v-4ba9589d><header class="header" data-v-780415cf data-v-4ba9589d><div class="header-navbar" data-v-780415cf><div class="flex-xbc main header-nav" data-v-780415cf><div class="nav-link" data-v-780415cf><a href="/" class="inblock link-logo router-link-active" data-v-780415cf><img data-src="/logo_hci.png" loading="lazy" alt="logo" class="logo-img lazy" data-v-780415cf></a> <br data-v-780415cf> <nav class="link-list" data-v-780415cf><a href="/" class="list-item router-link-active" data-v-780415cf>Home</a><a href="/hci_at_tufts/" class="list-item" data-v-780415cf>HCI At Tufts</a><a href="/people/" class="list-item" data-v-780415cf>People</a><a href="/projects/" class="list-item" data-v-780415cf>Projects</a><a href="/publications/" class="list-item" data-v-780415cf>Publications</a><a href="/code_and_datasets/" class="list-item router-link-active" data-v-780415cf>Code &amp; Datasets</a><a href="/admissions/" class="list-item" data-v-780415cf>Admissions</a><a href="/hci_resources/" class="list-item" data-v-780415cf>HCI Resources</a></nav></div> <!----></div></div> </header> <!----> <section class="page" data-v-4ba9589d data-v-4ba9589d><section class="info" style="background-image:url(/code_and_datasets/fNIRS.png);" data-v-441751fb><article class="main info-content" data-v-22a41398 data-v-441751fb><div class="content-header" data-v-22a41398><h1 class="header-title" data-v-22a41398>The Tufts fNIRS to Mental Workload Dataset</h1></div> <div class="flex-wcc content-tag" data-v-22a41398><div class="inblock tag-list" data-v-22a41398><a href="/category/null/" class="tag-text" data-v-22a41398>
      </a></div> <span class="tag-space" data-v-22a41398>/</span> <div class="inblock tag-list" data-v-22a41398><a href="/tag/BCI/" class="tag-text" data-v-22a41398>BCI
      </a><a href="/tag/Public Dataset/" class="tag-text" data-v-22a41398>Public Dataset
      </a><a href="/tag/fNIRS/" class="tag-text" data-v-22a41398>fNIRS
      </a><a href="/tag/machine learning/" class="tag-text" data-v-22a41398>machine learning
      </a><a href="/tag/time-series classification/" class="tag-text" data-v-22a41398>time-series classification
      </a><a href="/tag/cognitive workload/" class="tag-text" data-v-22a41398>cognitive workload
      </a></div></div> <div class="content content__default" data-v-22a41398><p>Currently, we are waiting for the Tufts IRB to give us permission to release the participants' data. (We are almost there, and we apologize for the inconvenience).</p> <p>If you want to download the data or have any questions, please reach out to Leon (leonwang_at_cs.tufts.edu).</p> <hr> <h2 id="paper-information"><a href="#paper-information" class="header-anchor">#</a> Paper Information</h2> <p>Zhe Huang*, Liang Wang*, Giles Blaney, Christopher Slaughter, Devon McKeon, Ziyu Zhou, Alex Olwal, Robert Jacob*, Michael C Hughes*
“The Tufts fNIRS to Mental Workload Dataset: Toward Brain-Computer Interfaces that Generalize” NeurIPS 2021 Datasets and Benchmarks Track (Round 2)</p> <p>*Lead authors ZH &amp; LW contributed equally, as did supervisory authors RJ &amp; MCH</p> <hr> <h2 id="project-description"><a href="#project-description" class="header-anchor">#</a> Project Description</h2> <p>Functional near-infrared spectroscopy (fNIRS) promises a non-intrusive way to measure real-time brain activity and build responsive brain-computer interfaces. However, in its first decade of research this technology has not yet realized its potential.</p> <ul><li><p>One common <strong>barrier</strong> to effective fNIRS-based BCIs is <strong><em>the lack of available data</em></strong>. Previous work typically collects proprietary datasets from only 10-20 subjects.</p></li> <li><p>Another <strong>barrier</strong> to progress is the lack of a <strong><em>standardized evaluation protocol</em></strong>. Without standardized protocols, different papers may not follow the very same experimental design, making results incomparable and preventing scientific progress.</p></li> <li><p>The toughest <strong>barrier</strong> of all to developing an accurate mental workload classifier is <strong><em>the high variation in fNIRS data</em></strong>, which makes generalizing to a new subject or session challenging.</p></li></ul> <hr> <p>Our <strong>contributions</strong> are:</p> <ul><li><p>We release <strong><em>a large open-access dataset</em></strong> of <code>68</code> participants. This dataset is the largest known to us by a factor of <code>2.5</code>. Details are in <a href="">Section Dataset</a> below.</p></li> <li><p>We suggest a standardized evaluation practice for assessing method performance on our dataset under three paradigms of training (clear instructions and code are provided in <a href="">Section Code</a> below):</p> <ul><li>subject-specific,</li> <li>generic,</li> <li>generic + fine-tuning.</li></ul></li></ul> <hr> <h2 id="dataset"><a href="#dataset" class="header-anchor">#</a> Dataset</h2> <p>Public dataset release pending imminent approval from IRB.
</p> <hr> <h3 id="data-description"><a href="#data-description" class="header-anchor">#</a> Data Description</h3> <p>Totally, our large open-access dataset includes <code>68</code> participants. Each subject contributes <code>21.33</code> minutes of fNIRS recordings from a controlled experimental setting with corresponding labels of workload intensity.</p> <hr> <p>Our released dataset includes:</p> <ul><li><strong>fNIRS recordings</strong> in <a href="">fNIRS_data</a>;</li> <li><strong>Supplementary data</strong>:
<ul><li><strong>demographic and contextual information</strong> in <a href="">pre-experiment</a>;</li> <li><strong>Cognitive task performance</strong> in <a href="">task_accuracy</a>;</li> <li><strong>experiment log</strong> in <a href="">log</a>;</li> <li><strong>post-experiment interview</strong> in <a href="">interview</a>;</li> <li><strong>subjective workload</strong> in <a href="">nasa-tlx</a>;</li></ul></li></ul> <hr> <h3 id="data-structure"><a href="#data-structure" class="header-anchor">#</a> Data Structure</h3> <p>Dataset folder structure is as below:
.</p> <ul><li><p>qualified_subjects_list.pdf</p></li> <li><p>pre-experiment</p> <ul><li>sub_xx.csv</li></ul></li> <li><p>experiment</p> <ul><li>log
<ul><li>sub_xx.csv</li></ul></li> <li>task_accuracy
<ul><li>sub_xx.csv</li></ul></li> <li>fNIRS_data
<ul><li>raw_data
<ul><li>sub_xx.csv</li></ul></li> <li>no_band_pass_filtered
<ul><li>sub_xx.csv</li></ul></li> <li>band_pass_filtered
<ul><li>bpf_whole_data
<ul><li>sub_xx.csv</li></ul></li> <li>bpf_slide_window_data
<ul><li>bpf_size_2sec_10ts_stride_3ts
<ul><li>sub_xx.csv</li></ul></li> <li>bpf_size_5sec_25ts_stride_3ts
<ul><li>sub_xx.csv</li></ul></li> <li>bpf_size_10sec_50ts_stride_3ts
<ul><li>sub_xx.csv</li></ul></li> <li>bpf_size_20sec_100ts_stride_3ts
<ul><li>sub_xx.csv</li></ul></li> <li>bpf_size_30sec_150ts_stride_3ts
<ul><li>sub_xx.csv</li></ul></li> <li>bpf_size_40sec_200ts_stride_3ts
<ul><li>sub_xx.csv</li></ul></li></ul></li></ul></li></ul></li></ul></li> <li><p>post-experiment</p> <ul><li>nasa-tlx
<ul><li>sub_xx.csv</li></ul></li> <li>interview
<ul><li>sub_xx.pdf</li></ul></li></ul></li></ul> <div class="language- extra-class"><pre class="language-text"><code>|- qualified_subjects_list.pdf            
|- pre-experiment                    //
|- experiment                        //
| |- log                             //
| |- task_accuracy                   //
| |- fNIRS_data                      //
| | |- raw_data                      //
| | |- no_band_pass_filtered         //
| | |- band_pass_filtered            //
| | | |- bpf_whole_data              //
| | | |- bpf_slide_window_data       //
| | | | |- bpf_size_2sec_10ts_stride_3ts
| | | | |- bpf_size_5sec_25ts_stride_3ts
| | | | |- bpf_size_10sec_50ts_stride_3ts
| | | | |- bpf_size_20sec_100ts_stride_3ts
| | | | |- bpf_size_30sec_50ts_stride_3ts
| | | | |- bpf_size_40sec_200ts_stride_3ts
|- post-experiment                   //
| |- nasa-tlx                        //
| |- interview                       //
| |- * (all other folders)  
</code></pre></div><hr> <h3 id="data-format"><a href="#data-format" class="header-anchor">#</a> Data Format</h3> <p>We introduce and describe the data format of fNIRS data (raw and pre-processed) and supplementary data as below:</p> <hr> <h4 id="experiment-data"><a href="#experiment-data" class="header-anchor">#</a> Experiment Data</h4> <p>All fNIRS data store here, along with the n-back tasks accuracy and experiment log.</p> <ol><li>raw data;</li> <li>band-pass-filtered;
2.a. bpf_raw_data;
2.b. bpf_filtered_slide_window_data;</li></ol> <h4 id="post-experiment-data"><a href="#post-experiment-data" class="header-anchor">#</a> Post-experiment Data</h4> <h4 id="supplementary-data"><a href="#supplementary-data" class="header-anchor">#</a> Supplementary Data</h4> <h5 id="demographic-and-contextual-information"><a href="#demographic-and-contextual-information" class="header-anchor">#</a> Demographic and contextual information</h5> <h5 id="subjective-workload"><a href="#subjective-workload" class="header-anchor">#</a> Subjective workload</h5> <h5 id="post-experiment-interview"><a href="#post-experiment-interview" class="header-anchor">#</a> Post-experiment interview</h5> <h2 id="code"><a href="#code" class="header-anchor">#</a> Code</h2> <h2 id="paper-link-and-please-cite"><a href="#paper-link-and-please-cite" class="header-anchor">#</a> Paper link and Please Cite</h2> <p><a href="https://openreview.net/forum?id=QzNHE7QHhut" target="_blank" rel="noopener noreferrer">Paper link<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></p></div> <div class="content-time" data-v-22a41398><time datetime="Feb 19, 2019" class="time-text" data-v-22a41398>Create Time: Feb 19, 2019
    </time> <time datetime="Aug 26, 2021" class="time-text" data-v-22a41398>Last Updated: Aug 26, 2021
    </time></div></article> <section class="flex-xb main info-nav" data-v-64012905 data-v-441751fb><!----> <a href="/code_and_datasets/UIST2021.html" class="flex-xb nav-item" data-v-64012905><div class="flex-xcc item-img" data-v-64012905><img data-src="/code_and_datasets/three_phases.png" loading="lazy" alt="Taming fNIRS-based BCI Input for Better Calibration and Broader Use" class="img lazy" data-v-64012905></div> <article class="flex-ysc item-content" data-v-64012905><h2 class="content-title" data-v-64012905>Taming fNIRS-based BCI Input for Better Calibration and Broader Use</h2> <div class="content" data-v-64012905></div></article></a></section> <!----></section></section> <div data-v-55aa431a data-v-4ba9589d><div class="my-box" data-v-55aa431a></div> <footer class="footer" data-v-55aa431a><nav class="link-list" data-v-55aa431a><a href="/code_and_datasets/fNIRS2MW.html" aria-current="page" class="list-item router-link-exact-active router-link-active" data-v-55aa431a>HCI Lab, Department of Computer Science 196 Boston Ave., Tufts University, Medford, MA, 02155</a></nav> <a href="/" class="copyright router-link-active" data-v-55aa431a>Copyright  ©  Tufts University School of Engineering. All Rights Reserved.
      </a></footer></div></section><div class="global-ui"><!----><!----></div></div>
    <script src="/assets/js/app.4c03d920.js" defer></script><script src="/assets/js/11.a5b16cad.js" defer></script>
  </body>
</html>
