<!DOCTYPE html>
<html lang="en-US">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <title>The Tufts fNIRS to Mental Workload Dataset | Tufts HCI Lab</title>
    <meta name="generator" content="VuePress 1.8.2">
    
    <meta name="description" content="Tufts Human-Computer Interaction Laboratory">
    
    <link rel="preload" href="/assets/css/0.styles.3208571a.css" as="style"><link rel="preload" href="/assets/js/app.9e3c66ad.js" as="script"><link rel="preload" href="/assets/js/10.58381bb4.js" as="script"><link rel="prefetch" href="/assets/js/11.9e5ea432.js"><link rel="prefetch" href="/assets/js/12.f100cdea.js"><link rel="prefetch" href="/assets/js/13.6e632d88.js"><link rel="prefetch" href="/assets/js/14.b22428f9.js"><link rel="prefetch" href="/assets/js/15.12b7bd5c.js"><link rel="prefetch" href="/assets/js/16.b4b76b3a.js"><link rel="prefetch" href="/assets/js/17.29ce64e5.js"><link rel="prefetch" href="/assets/js/18.cd3154d8.js"><link rel="prefetch" href="/assets/js/19.cc53e73e.js"><link rel="prefetch" href="/assets/js/2.5463c4c1.js"><link rel="prefetch" href="/assets/js/20.fa8d684e.js"><link rel="prefetch" href="/assets/js/21.a999e5e3.js"><link rel="prefetch" href="/assets/js/22.b1fa12c4.js"><link rel="prefetch" href="/assets/js/23.53907abe.js"><link rel="prefetch" href="/assets/js/24.18bf5c97.js"><link rel="prefetch" href="/assets/js/25.b55e6a15.js"><link rel="prefetch" href="/assets/js/26.fa67aaae.js"><link rel="prefetch" href="/assets/js/27.59a15909.js"><link rel="prefetch" href="/assets/js/28.c5f52327.js"><link rel="prefetch" href="/assets/js/29.73cef242.js"><link rel="prefetch" href="/assets/js/3.e8f94cd8.js"><link rel="prefetch" href="/assets/js/30.fe52c01d.js"><link rel="prefetch" href="/assets/js/31.853edc2f.js"><link rel="prefetch" href="/assets/js/32.6bc87f99.js"><link rel="prefetch" href="/assets/js/33.778ce70b.js"><link rel="prefetch" href="/assets/js/34.4b401844.js"><link rel="prefetch" href="/assets/js/35.50234c1c.js"><link rel="prefetch" href="/assets/js/36.ab0a0d0a.js"><link rel="prefetch" href="/assets/js/37.775cd637.js"><link rel="prefetch" href="/assets/js/38.f7b75fc9.js"><link rel="prefetch" href="/assets/js/39.3c58ec0a.js"><link rel="prefetch" href="/assets/js/4.9d16c770.js"><link rel="prefetch" href="/assets/js/5.b529b20a.js"><link rel="prefetch" href="/assets/js/6.100ef550.js"><link rel="prefetch" href="/assets/js/7.105519d6.js"><link rel="prefetch" href="/assets/js/8.54e1ea8b.js"><link rel="prefetch" href="/assets/js/9.dbc5c4f5.js">
    <link rel="stylesheet" href="/assets/css/0.styles.3208571a.css">
  </head>
  <body>
    <div id="app" data-server-rendered="true"><section id="global-layout" data-v-4ba9589d><header class="header" data-v-780415cf data-v-4ba9589d><div class="header-navbar" data-v-780415cf><div class="flex-xbc main header-nav" data-v-780415cf><div class="nav-link" data-v-780415cf><a href="/" class="inblock link-logo router-link-active" data-v-780415cf><img data-src="/logo_hci.png" loading="lazy" alt="logo" class="logo-img lazy" data-v-780415cf></a> <br data-v-780415cf> <nav class="link-list" data-v-780415cf><a href="/" class="list-item router-link-active" data-v-780415cf>Home</a><a href="/hci_at_tufts/" class="list-item" data-v-780415cf>HCI At Tufts</a><a href="/people/" class="list-item" data-v-780415cf>People</a><a href="/projects/" class="list-item" data-v-780415cf>Projects</a><a href="/publications/" class="list-item" data-v-780415cf>Publications</a><a href="/code_and_datasets/" class="list-item router-link-active" data-v-780415cf>Code &amp; Datasets</a><a href="/admissions/" class="list-item" data-v-780415cf>Admissions</a><a href="/hci_resources/" class="list-item" data-v-780415cf>HCI Resources</a></nav></div> <!----></div></div> </header> <!----> <section class="page" data-v-4ba9589d data-v-4ba9589d><section class="info" style="background-image:url(/code_and_datasets/fNIRS.png);" data-v-441751fb><article class="main info-content" data-v-22a41398 data-v-441751fb><div class="content-header" data-v-22a41398><h1 class="header-title" data-v-22a41398>The Tufts fNIRS to Mental Workload Dataset</h1></div> <div class="flex-wcc content-tag" data-v-22a41398><div class="inblock tag-list" data-v-22a41398><a href="/category/null/" class="tag-text" data-v-22a41398>
      </a></div> <span class="tag-space" data-v-22a41398>/</span> <div class="inblock tag-list" data-v-22a41398><a href="/tag/BCI/" class="tag-text" data-v-22a41398>BCI
      </a><a href="/tag/Public Dataset/" class="tag-text" data-v-22a41398>Public Dataset
      </a><a href="/tag/fNIRS/" class="tag-text" data-v-22a41398>fNIRS
      </a><a href="/tag/machine learning/" class="tag-text" data-v-22a41398>machine learning
      </a><a href="/tag/time-series classification/" class="tag-text" data-v-22a41398>time-series classification
      </a><a href="/tag/cognitive workload/" class="tag-text" data-v-22a41398>cognitive workload
      </a></div></div> <div class="content content__default" data-v-22a41398><p>Currently, we are waiting for the Tufts IRB to give us permission to release the participants' data. (We are almost there, and we apologize for the inconvenience).</p> <p>If you want to download the data or have any questions, please reach out to Leon (leonwang_at_cs.tufts.edu).</p> <h2 id="paper-information"><a href="#paper-information" class="header-anchor">#</a> Paper Information</h2> <p>Zhe Huang*, Liang Wang*, Giles Blaney, Christopher Slaughter, Devon McKeon, Ziyu Zhou, Alex Olwal, Robert Jacob*, Michael C Hughes*
“The Tufts fNIRS to Mental Workload Dataset: Toward Brain-Computer Interfaces that Generalize” NeurIPS 2021 Datasets and Benchmarks Track (Round 2)</p> <p>*Lead authors ZH &amp; LW contributed equally, as did supervisory authors RJ &amp; MCH</p> <h2 id="description"><a href="#description" class="header-anchor">#</a> Description</h2> <p>Functional near-infrared spectroscopy (fNIRS) promises a non-intrusive way to measure real-time brain activity and build responsive brain-computer interfaces. However, in its first decade of research this technology has not yet realized its potential.</p> <ul><li><p>One common <strong>barrier</strong> to effective fNIRS-based BCIs is <strong><em>the lack of available data</em></strong>. Previous work typically collects proprietary datasets from only 10-20 subjects.</p></li> <li><p>Another <strong>barrier</strong> to progress is the lack of a <strong><em>standardized evaluation protocol</em></strong>. Without standardized protocols, different papers may not follow the very same experimental design, making results incomparable and preventing scientific progress.</p></li> <li><p>The toughest <strong>barrier</strong> of all to developing an accurate mental workload classifier is <strong><em>the high variation in fNIRS data</em></strong>, which makes generalizing to a new subject or session challenging.</p></li></ul> <p>Our <strong>contributions</strong> are:</p> <ul><li><p>We release a large open-access dataset of 68 participants. This dataset is the largest known to us by a factor of 2.5. Details are in <a href="">Section Dataset</a> below.</p></li> <li><p>We suggest a standardized evaluation practice for assessing method performance on our dataset under three paradigms of training: subject-specific, generic, and generic + fine-tuning. clear instructions and code are provided in <a href="">Section Code</a> below.</p></li></ul> <h2 id="dataset"><a href="#dataset" class="header-anchor">#</a> Dataset</h2> <p>Public dataset release pending imminent approval from IRB.
</p> <h3 id="data-description"><a href="#data-description" class="header-anchor">#</a> Data Description</h3> <h3 id="data-structure"><a href="#data-structure" class="header-anchor">#</a> Data Structure</h3> <h3 id="data-format"><a href="#data-format" class="header-anchor">#</a> Data Format</h3> <h4 id="pre-experiment"><a href="#pre-experiment" class="header-anchor">#</a> Pre-experiment</h4> <p>It includes the non sensitive personal data we collect before the experiment.</p> <h4 id="experiment-data"><a href="#experiment-data" class="header-anchor">#</a> Experiment Data</h4> <p>All fNIRS data store here, along with the n-back tasks accuracy and experiment log.</p> <ol><li>raw data;</li> <li>band-pass-filtered;
2.a. bpf_raw_data;
2.b. bpf_filtered_slide_window_data;</li></ol> <h4 id="supplementary-data"><a href="#supplementary-data" class="header-anchor">#</a> Supplementary Data</h4> <h5 id="demographic-and-contextual-information"><a href="#demographic-and-contextual-information" class="header-anchor">#</a> Demographic and contextual information</h5> <h5 id="subjective-workload"><a href="#subjective-workload" class="header-anchor">#</a> Subjective workload</h5> <h5 id="post-experiment-interview"><a href="#post-experiment-interview" class="header-anchor">#</a> Post-experiment interview</h5> <h2 id="code"><a href="#code" class="header-anchor">#</a> Code</h2> <h2 id="paper-link-and-please-cite"><a href="#paper-link-and-please-cite" class="header-anchor">#</a> Paper link and Please Cite</h2> <p><a href="https://openreview.net/forum?id=QzNHE7QHhut" target="_blank" rel="noopener noreferrer">Paper link<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></p></div> <div class="content-time" data-v-22a41398><time datetime="Feb 19, 2019" class="time-text" data-v-22a41398>Create Time: Feb 19, 2019
    </time> <time datetime="Aug 25, 2021" class="time-text" data-v-22a41398>Last Updated: Aug 25, 2021
    </time></div></article> <section class="flex-xb main info-nav" data-v-64012905 data-v-441751fb><!----> <a href="/code_and_datasets/UIST2021.html" class="flex-xb nav-item" data-v-64012905><div class="flex-xcc item-img" data-v-64012905><img data-src="/code_and_datasets/three_phases.png" loading="lazy" alt="Taming fNIRS-based BCI Input for Better Calibration and Broader Use" class="img lazy" data-v-64012905></div> <article class="flex-ysc item-content" data-v-64012905><h2 class="content-title" data-v-64012905>Taming fNIRS-based BCI Input for Better Calibration and Broader Use</h2> <div class="content" data-v-64012905></div></article></a></section> <!----></section></section> <div data-v-55aa431a data-v-4ba9589d><div class="my-box" data-v-55aa431a></div> <footer class="footer" data-v-55aa431a><nav class="link-list" data-v-55aa431a><a href="/code_and_datasets/NeurIPS2021.html" aria-current="page" class="list-item router-link-exact-active router-link-active" data-v-55aa431a>HCI Lab, Department of Computer Science 196 Boston Ave., Tufts University, Medford, MA, 02155</a></nav> <a href="/" class="copyright router-link-active" data-v-55aa431a>Copyright  ©  Tufts University School of Engineering. All Rights Reserved.
      </a></footer></div></section><div class="global-ui"><!----><!----></div></div>
    <script src="/assets/js/app.9e3c66ad.js" defer></script><script src="/assets/js/10.58381bb4.js" defer></script>
  </body>
</html>
